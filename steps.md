
ggml
https://ggml-python.readthedocs.io/en/latest/

https://inference.readthedocs.io/zh-cn/latest/index.html
https://huggingface.co/models
https://modelscope.cn/models

https://python.langchain.com/docs/use_cases/question_answering/
https://learn.deeplearning.ai/

https://gptcache.readthedocs.io/en/latest/bootcamp/langchain/qa_generation.html

```txt
1. type1 chat with Xinference and ollama    OK
2. RAG  OK
3. QA   process
4. strut data SQL?



1. source pdf / world / ecxcel
1.1 split

2. vectorstore
2.1 read and store vectorstore DB

3. RAG
3.1 Use llm search in vectorstore
```

```txt
# local
Xinference
ollama

# saas
openai
azure
```

```txt
langchain
LlamaIndex
Deepset Haystack
```
